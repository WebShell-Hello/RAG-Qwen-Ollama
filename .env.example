# Ollama server URL (host running Ollama)
OLLAMA_URL=http://localhost:11434

# Chat model name as available in Ollama (e.g. qwen/qwen-3b)
CHAT_MODEL=qwen/qwen-3b

# Embedding model name (as pulled in Ollama)
EMBED_MODEL=nomic-embed-text

# FAISS index and metadata paths (created by ingest.py)
FAISS_PATH=wm_manual.faiss
META_PATH=wm_manual_meta.json

# App settings
TOP_K=4
